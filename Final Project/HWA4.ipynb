{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # used for scientific computing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd # used for data analysis and manipulation\n",
    "import matplotlib.pyplot as plt # used for visualization and plotting\n",
    "import matplotlib.cm as cm\n",
    "import scipy as sp\n",
    "import pprint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import metrics\n",
    "import dtreeviz.trees\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import pprint\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for min coefficients\n",
    "split to train/test by applicant, not randomally\n",
    "validity of data (preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('inner_data.csv')\n",
    "column_headers = list(df.columns.values)\n",
    "data = df.to_numpy()\n",
    "len(column_headers)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:, 1:]\n",
    "data = data[:, 1:]\n",
    "# X = np.delete(data, feature, axis=1)\n",
    "# y = data[:, feature]\n",
    "column_headers.pop(0)\n",
    "column_headers.pop(0)\n",
    "data.shape\n",
    "# len(column_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_best_features(X_train_poly, X_test_poly, y_train, y_test, num_feat, thresh=0.1):\n",
    "    # Train the polynomial regression model\n",
    "    model = LinearRegression()\n",
    "    # print(X_train_poly.shape, y_train.shape)\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    # Predict on the testing set\n",
    "    y_pred = model.predict(X_test_poly)\n",
    "\n",
    "    # # Calculate mean squared error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"Mean Squared Error:\", \"{:.4f}\".format(mse))\n",
    "    pred_comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "    pred_comparison_df[\"True/False\"] = np.abs(pred_comparison_df[\"Actual\"] - pred_comparison_df[\"Predicted\"]) < thresh        \n",
    "    print(\"Accuracy: \",\"{:.2f}\".format(100*pred_comparison_df[\"True/False\"].value_counts(normalize=True)[0]),\"%\")\n",
    "    \n",
    "    feature_coefficients = np.abs(model.coef_)\n",
    "    # Get the indices of the top 5 features with the highest coefficients\n",
    "    top5_indices = np.argsort(feature_coefficients)[-num_feat:]\n",
    "    # print(top5_indices)\n",
    "    # Get the names of the top 5 features\n",
    "    # top5_features = poly_names[top5_indices]  # Replace 'feature_names' with the actual names of your features\n",
    "\n",
    "    # Print the top 5 features\n",
    "    # print(\"Top 5 Features:\")\n",
    "    # for feature in top5_features:\n",
    "    #     print(feature)\n",
    "    return top5_indices.tolist(), mse, pred_comparison_df[\"True/False\"].value_counts(normalize=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_to_poly_data(X_train, X_test, degree):\n",
    "    # Create polynomial features\n",
    "    poly_features = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly_features.fit_transform(X_train)\n",
    "    X_test_poly = poly_features.transform(X_test)\n",
    "    poly_names = poly_features.get_feature_names_out()\n",
    "    return X_train_poly, X_test_poly, poly_names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_by_feature(df, feature):\n",
    "    data =df.to_numpy()\n",
    "    data = data[:, 1:]\n",
    "    data = data[:, 1:]\n",
    "    X = np.delete(data, feature, axis=1)\n",
    "    y = data[:, feature]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def split_data_by_applicant(df, feature):\n",
    "    applicants = df.Applicant.unique()\n",
    "    applicants_train, applicants_test = train_test_split(applicants, test_size=0.2, random_state=42)\n",
    "    data_train = df[df.Applicant.isin(applicants_train)].copy()\n",
    "    data_test = df[df.Applicant.isin(applicants_test)].copy()\n",
    "    data_train.drop(columns=['Question','Applicant'], inplace=True)\n",
    "    data_test.drop(columns=['Question','Applicant'], inplace=True)\n",
    "\n",
    "    data_train=data_train.to_numpy()\n",
    "    data_test=data_test.to_numpy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = np.delete(data_train, feature, axis=1),np.delete(data_test, feature, axis=1), data_train[:, feature],data_test[:, feature]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_by_feature(df, degree, thresh, num_feat):\n",
    "    best_features = []\n",
    "    best_features_to_predict = {}\n",
    "    for feature in range(df.shape[1]-2):\n",
    "        print(\"FEATURE TO PREDICT: \", feature)\n",
    "        X_train, X_test, y_train, y_test = split_data_by_feature(df, feature)\n",
    "        X_train_poly, X_test_poly, poly_names = linear_to_poly_data(X_train, X_test, degree)\n",
    "        model_eval = provide_best_features(X_train_poly, X_test_poly, y_train, y_test, num_feat)\n",
    "        top_features = poly_names[model_eval[0]].tolist()\n",
    "        best_features.append(model_eval[0])\n",
    "\n",
    "        print(\"\\npredict only with TOP 5 features:\")\n",
    "        X_train_only_best, X_test_only_best = X_train_poly[:,best_features[feature]], X_test_poly[:, best_features[feature]]\n",
    "        limited_model_eval = provide_best_features(X_train_only_best, X_test_only_best, y_train, y_test, num_feat)\n",
    "        if limited_model_eval[2]/model_eval[2] >= thresh:\n",
    "            best_features_to_predict[feature] = {'feature names':top_features,'feature numbers':model_eval[0], 'mse':model_eval[1],'accuracy':model_eval[2],'limited model mse': limited_model_eval[1],'limited model accuracy': limited_model_eval[2], 'ratio':limited_model_eval[2]/model_eval[2]}\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    pprint.pprint(best_features_to_predict)\n",
    "    return best_features_to_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_by_applicant(df, degree, thresh, num_feat):\n",
    "    best_features = []\n",
    "    best_features_to_predict = {}\n",
    "    for feature in range(df.shape[1]-2):\n",
    "        print(\"FEATURE TO PREDICT: \", feature)\n",
    "        X_train, X_test, y_train, y_test = split_data_by_applicant(df, feature)\n",
    "        X_train_poly, X_test_poly, poly_names = linear_to_poly_data(X_train, X_test, degree)\n",
    "        model_eval = provide_best_features(X_train_poly, X_test_poly, y_train, y_test, num_feat)\n",
    "        top_features = poly_names[model_eval[0]].tolist()\n",
    "        best_features.append(model_eval[0])\n",
    "\n",
    "        print(\"\\npredict only with TOP features:\")\n",
    "        X_train_only_best, X_test_only_best = X_train_poly[:,best_features[feature]], X_test_poly[:, best_features[feature]]\n",
    "        limited_model_eval = provide_best_features(X_train_only_best, X_test_only_best, y_train, y_test, num_feat)\n",
    "        if limited_model_eval[2]/model_eval[2] >= thresh:\n",
    "            best_features_to_predict[feature] = {'feature names':top_features,'feature numbers':model_eval[0], 'mse':model_eval[1],'accuracy':model_eval[2],'limited model mse': limited_model_eval[1],'limited model accuracy': limited_model_eval[2], 'ratio':limited_model_eval[2]/model_eval[2]}\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    pprint.pprint(best_features_to_predict)\n",
    "    return best_features_to_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the program\n",
    "degree = 1\n",
    "thresh = 0.9\n",
    "num_feat = 2\n",
    "best_feat = run_model_by_feature(df,degree, thresh,num_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the program\n",
    "degree = 1\n",
    "thresh = 0.9\n",
    "num_feat = 2\n",
    "best_feat = run_model_by_applicant(df,degree, thresh,num_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(best_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('inner_data.csv')\n",
    "column_headers = list(df.columns.values)\n",
    "data1= df.groupby('Applicant').mean()\n",
    "data1.drop(columns=['Question'], inplace=True)\n",
    "# data1 = data1.to_numpy()\n",
    "# data1.shape\n",
    "data1 = data1.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the program\n",
    "degree = 1\n",
    "thresh = 0.9\n",
    "num_feat = 2\n",
    "best_features = []\n",
    "best_features_to_predict = {}\n",
    "\n",
    "# for feature in range(X_train.shape[1]):\n",
    "# def test_model_by_feature(data, )\n",
    "for feature in range(82):\n",
    "    print(\"FEATURE TO PREDICT: \", feature)\n",
    "    X_train, X_test, y_train, y_test = split_data_by_feature(df, feature)\n",
    "    X_train_poly, X_test_poly, poly_names = linear_to_poly_data(X_train, X_test, degree)\n",
    "    model_eval = provide_best_features(X_train_poly, X_test_poly, y_train, y_test, num_feat)\n",
    "    top_features = poly_names[model_eval[0]].tolist()\n",
    "    best_features.append(model_eval[0])\n",
    "\n",
    "    print(\"\\npredict only with TOP 5 features:\")\n",
    "    X_train_only_best, X_test_only_best = X_train_poly[:,best_features[feature]], X_test_poly[:, best_features[feature]]\n",
    "    limited_model_eval = provide_best_features(X_train_only_best, X_test_only_best, y_train, y_test, num_feat)\n",
    "    if limited_model_eval[2]/model_eval[2] >= .9:\n",
    "        best_features_to_predict[feature] = {'feature names':top_features,'feature numbers':model_eval[0], 'mse':model_eval[1],'accuracy':model_eval[2],'limited model mse': limited_model_eval[1],'limited model accuracy': limited_model_eval[2], 'ratio':limited_model_eval[2]/model_eval[2]}\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "pprint.pprint(best_features_to_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(best_features_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('inner_data.csv')\n",
    "column_headers = list(df.columns.values)\n",
    "def split_data_by_applicant(df, feature):\n",
    "    applicants = df.Applicant.unique()\n",
    "    applicants_train, applicants_test = train_test_split(applicants, test_size=0.2, random_state=42)\n",
    "    # print(applicants_train)\n",
    "    data_train = df[df.Applicant.isin(applicants_train)].copy()\n",
    "    data_test = df[df.Applicant.isin(applicants_test)].copy()\n",
    "    data_train.drop(columns=['Question','Applicant'], inplace=True)\n",
    "    data_test.drop(columns=['Question','Applicant'], inplace=True)\n",
    "    # print(data_train, data_test)\n",
    "\n",
    "    data_train=data_train.to_numpy()\n",
    "    data_test=data_test.to_numpy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = np.delete(data_train, feature, axis=1),np.delete(data_test, feature, axis=1), data_train[:, feature],data_test[:, feature]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run the program\n",
    "# degree = 1\n",
    "# thresh = 0.9\n",
    "# num_feat = 2\n",
    "# best_features = []\n",
    "# best_features_to_predict = {}\n",
    "# df = pd.read_csv('inner_data.csv')\n",
    "\n",
    "# # for feature in range(X_train.shape[1]):\n",
    "# for feature in range(82):\n",
    "#     print(\"FEATURE TO PREDICT: \", feature)\n",
    "#     X_train, X_test, y_train, y_test = split_data_by_applicant(df, feature)\n",
    "#     X_train_poly, X_test_poly, poly_names = linear_to_poly_data(X_train, X_test, degree)\n",
    "#     model_eval = provide_best_features(X_train_poly, X_test_poly, y_train, y_test, num_feat)\n",
    "#     top_features = poly_names[model_eval[0]].tolist()\n",
    "#     best_features.append(model_eval[0])\n",
    "\n",
    "#     print(\"\\npredict only with TOP 5 features:\")\n",
    "#     X_train_only_best, X_test_only_best = X_train_poly[:,best_features[feature]], X_test_poly[:, best_features[feature]]\n",
    "#     limited_model_eval = provide_best_features(X_train_only_best, X_test_only_best, y_train, y_test, num_feat)\n",
    "#     if limited_model_eval[2]/model_eval[2] >= thresh:\n",
    "#         best_features_to_predict[feature] = {'feature names':top_features,'feature numbers':model_eval[0], 'mse':model_eval[1],'accuracy':model_eval[2],'limited model mse': limited_model_eval[1],'limited model accuracy': limited_model_eval[2], 'ratio':limited_model_eval[2]/model_eval[2]}\n",
    "#     print(\"\\n\\n\")\n",
    "\n",
    "# pprint.pprint(best_features_to_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(best_features_to_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
